{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5beb1241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/03 07:19:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/03 07:19:15 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Start notebook\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.119:7077\") \\\n",
    "        .appName(\"victor_hwasser_applicationB\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075d8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "#conf = spark_session.conf\n",
    "sc = spark_session.sparkContext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf9d8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor this section, we’ll use the PySpark DataFrames/SQL API. Use the existing cluster, and a\\nnotebook on your own client machine, which you must deploy yourself.\\nWe’ll work with a large dataset in CSV format. Our dataset is the Los Angeles Parking\\nCitations (https://www.kaggle.com/cityofLA/los-angeles-parking-citations). I have pre-loaded\\nthe dataset into the HDFS cluster.\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For this section, we’ll use the PySpark DataFrames/SQL API. Use the existing cluster, and a\n",
    "notebook on your own client machine, which you must deploy yourself.\n",
    "We’ll work with a large dataset in CSV format. Our dataset is the Los Angeles Parking\n",
    "Citations (https://www.kaggle.com/cityofLA/los-angeles-parking-citations). I have pre-loaded\n",
    "the dataset into the HDFS cluster.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f325593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "|Ticket number|          Issue Date|Issue time|Meter Id|Marked Time|RP State Plate|Plate Expiry Date| VIN|Make|Body Style|Color|            Location|Route|Agency|Violation code|Violation Description|Fine amount| Latitude|Longitude|Agency Description|Color Description|Body Style Description|\n",
      "+-------------+--------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "|   1103341116|2015-12-21T00:00:...|      1251|    null|       null|            CA|           200304|null|HOND|        PA|   GY|     13147 WELBY WAY|01521|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              null|             null|                  null|\n",
      "|   1103700150|2015-12-21T00:00:...|      1435|    null|       null|            CA|           201512|null| GMC|        VN|   WH|       525 S MAIN ST| 1C51|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              null|             null|                  null|\n",
      "|   1104803000|2015-12-21T00:00:...|      2055|    null|       null|            CA|           201503|null|NISS|        PA|   BK|       200 WORLD WAY|  2R2|     2|          8939|           WHITE CURB|         58|6439997.9|1802686.4|              null|             null|                  null|\n",
      "|   1104820732|2015-12-26T00:00:...|      1515|    null|       null|            CA|             null|null|ACUR|        PA|   WH|       100 WORLD WAY| 2F11|     2|           000|               17104h|       null|6440041.1|1802686.2|              null|             null|                  null|\n",
      "|   1105461453|2015-09-15T00:00:...|       115|    null|       null|            CA|           200316|null|CHEV|        PA|   BK|  GEORGIA ST/OLYMPIC|1FB70|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1106226590|2015-09-15T00:00:...|        19|    null|       null|            CA|           201507|null|CHEV|        VN|   GY|  SAN PEDRO S/O BOYD|1A35W|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              null|             null|                  null|\n",
      "|   1106500452|2015-12-17T00:00:...|      1710|    null|       null|            CA|           201605|null|MAZD|        PA|   BL|     SUNSET/ALVARADO|00217|     1|          8070| PARK IN GRID LOCK ZN|        163|    99999|    99999|              null|             null|                  null|\n",
      "|   1106500463|2015-12-17T00:00:...|      1710|    null|       null|            CA|           201602|null|TOYO|        PA|   BK|     SUNSET/ALVARADO|00217|     1|          8070| PARK IN GRID LOCK ZN|        163|    99999|    99999|              null|             null|                  null|\n",
      "|   1106506402|2015-12-22T00:00:...|       945|    null|       null|            CA|           201605|null|CHEV|        PA|   BR|      721 S WESTLAKE| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1106506413|2015-12-22T00:00:...|      1100|    null|       null|            CA|           201701|null|NISS|        PA|   SI|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1106506424|2015-12-22T00:00:...|      1100|    null|       null|            CA|           201511|null|FORD|        TR|   WH|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1106506435|2015-12-22T00:00:...|      1105|    null|       null|            CA|           201701|null|CHRY|        PA|   GO|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1106506446|2015-12-22T00:00:...|      1110|    null|       null|            CA|           201511|null| BMW|        PA|   BK|      1200 W MIRAMAR| 2A75|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              null|             null|                  null|\n",
      "|   1106549754|2015-12-15T00:00:...|       825|    null|       null|            CA|           201607|null|PTRB|        TR|   BK|           4TH/STATE| CM96|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1107179581|2015-12-27T00:00:...|      1055|    null|       null|            CA|           201605|null|TOYO|        PA|   BK|3100 N HOLLYRIDGE DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|              null|             null|                  null|\n",
      "|   1107179592|2015-12-27T00:00:...|      1200|    null|       null|            CA|           201602|null|MBNZ|        PA|   BK|   3115 N BERENDO DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|              null|             null|                  null|\n",
      "|   1107179603|2015-12-27T00:00:...|      1400|    null|       null|            CA|           201611|null|NISS|        PA|   WH| 3100 N BEACHWOOD DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|              null|             null|                  null|\n",
      "|   1107539823|2015-09-16T00:00:...|      2120|    null|       null|            CA|           201502|null|NISS|        PA| null|      BLAINE/11TH PL|1FB95|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              null|             null|                  null|\n",
      "|   1107539834|2015-09-16T00:00:...|      1045|    null|       null|            CA|             null|null|CHEV|        PA|   BK|  1246 S FIGUEROA ST| 1L20|     1|        8069AP|     NO STOP/STAND PM|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1107780811|2015-12-22T00:00:...|      1102|    null|       null|            CA|           201606|null|HOND|        PA|   BK|       PLATA/RAMPART|  2A1|     1|         8069B|           NO PARKING|         73|    99999|    99999|              null|             null|                  null|\n",
      "+-------------+--------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.1 Load the CSV file from HDFS, and call show() to verify the data is loaded correctly.\n",
    "df = spark_session.read.csv('hdfs://192.168.2.119:9000/parking-citations.csv', header=True)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bbf5ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(Ticket number,StringType,true),StructField(Issue Date,StringType,true),StructField(Issue time,StringType,true),StructField(Meter Id,StringType,true),StructField(Marked Time,StringType,true),StructField(RP State Plate,StringType,true),StructField(Plate Expiry Date,StringType,true),StructField(VIN,StringType,true),StructField(Make,StringType,true),StructField(Body Style,StringType,true),StructField(Color,StringType,true),StructField(Location,StringType,true),StructField(Route,StringType,true),StructField(Agency,StringType,true),StructField(Violation code,StringType,true),StructField(Violation Description,StringType,true),StructField(Fine amount,StringType,true),StructField(Latitude,StringType,true),StructField(Longitude,StringType,true),StructField(Agency Description,StringType,true),StructField(Color Description,StringType,true),StructField(Body Style Description,StringType,true)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13077724\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# B.2 Print the schema for the DataFrame.\n",
    "\n",
    "print(df.schema)\n",
    "\n",
    "# B.3 Count the number of rows in the CSV file.\n",
    "\n",
    "df_count = df.count()\n",
    "print(df_count)\n",
    "\n",
    "# B.4 Count the number of partitions in the underlying RDD.\n",
    "\n",
    "print(df.rdd.getNumPartitions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bb317b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ticket number', 'Issue Date', 'Issue time', 'Meter Id', 'Marked Time', 'RP State Plate', 'Plate Expiry Date', 'Make', 'Body Style', 'Color', 'Location', 'Route', 'Agency', 'Violation code', 'Violation Description', 'Fine amount', 'Agency Description', 'Color Description', 'Body Style Description']\n"
     ]
    }
   ],
   "source": [
    "# B.5 Drop the columns VIN, Latitude and Longitude.\n",
    "\n",
    "columns_to_drop = ['VIN', 'Latitude', 'Longitude']\n",
    "for c in columns_to_drop:\n",
    "    df = df.drop(c)\n",
    "    \n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd51a115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine amount: 1100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many fines have this amount: 728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# B.6 Find the maximum fine amount. How many fines have this amount? \n",
    "# You need to convert the ‘fine amount’ column to a float to do this correctly.\n",
    "from pyspark.sql.functions import max, min \n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "df = df.withColumn(\"Fine amount\", df[\"Fine amount\"].cast(FloatType()))\n",
    "max_fine_amount = df.agg(max(\"Fine amount\")).collect()[0][0]\n",
    "all_max = df.filter(df['Fine amount'] == 98.0)\n",
    "print(\"Fine amount:\", max_fine_amount)\n",
    "print(\"How many fines have this amount:\", all_max.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7baad622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TOYT', 2150768), ('HOND', 1479996), ('FORD', 1116235), ('NISS', 945133), ('CHEV', 892676), ('BMW', 603092), ('MERZ', 543298), ('VOLK', 432030), ('HYUN', 404917), ('DODG', 391686), ('LEXS', 368420), ('KIA', 328155), ('JEEP', 316300), ('AUDI', 255395), ('MAZD', 242344), ('OTHR', 205546), ('GMC', 184889), ('INFI', 174315), ('CHRY', 159948), ('SUBA', 154640)]\n"
     ]
    }
   ],
   "source": [
    "# B.7 Show the top 20 most frequent vehicle makes, and their frequencies.\n",
    "# most_freq = df.agg(asc(\"Make\")).collect()[0][0]\n",
    "top_20_vec = df.rdd.map(lambda x: (x['Make'],1)).reduceByKey(lambda a, b: a+b)\n",
    "top_20_vec = top_20_vec.sortBy(lambda x: x[1], ascending=False)\n",
    "print(top_20_vec.take(20))\n",
    "\n",
    "# We can see that Toyota has the highest freqency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc319b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Ticket number='1103341116', Issue Date='2015-12-21T00:00:00.000', Issue time='1251', Meter Id=None, Marked Time=None, RP State Plate='CA', Plate Expiry Date='200304', Make='HOND', Body Style='PA', Color='GY', Location='13147 WELBY WAY', Route='01521', Agency='1', Violation code='4000A1', Violation Description='NO EVIDENCE OF REG', Fine amount=50.0, Agency Description=None, Color Description=None, Body Style Description=None, color long='Gray'), Row(Ticket number='1103700150', Issue Date='2015-12-21T00:00:00.000', Issue time='1435', Meter Id=None, Marked Time=None, RP State Plate='CA', Plate Expiry Date='201512', Make='GMC', Body Style='VN', Color='WH', Location='525 S MAIN ST', Route='1C51', Agency='1', Violation code='4000A1', Violation Description='NO EVIDENCE OF REG', Fine amount=50.0, Agency Description=None, Color Description=None, Body Style Description=None, color long='White'), Row(Ticket number='1104803000', Issue Date='2015-12-21T00:00:00.000', Issue time='2055', Meter Id=None, Marked Time=None, RP State Plate='CA', Plate Expiry Date='201503', Make='NISS', Body Style='PA', Color='BK', Location='200 WORLD WAY', Route='2R2', Agency='2', Violation code='8939', Violation Description='WHITE CURB', Fine amount=58.0, Agency Description=None, Color Description=None, Body Style Description=None, color long='Black'), Row(Ticket number='1104820732', Issue Date='2015-12-26T00:00:00.000', Issue time='1515', Meter Id=None, Marked Time=None, RP State Plate='CA', Plate Expiry Date=None, Make='ACUR', Body Style='PA', Color='WH', Location='100 WORLD WAY', Route='2F11', Agency='2', Violation code='000', Violation Description='17104h', Fine amount=None, Agency Description=None, Color Description=None, Body Style Description=None, color long='White'), Row(Ticket number='1105461453', Issue Date='2015-09-15T00:00:00.000', Issue time='115', Meter Id=None, Marked Time=None, RP State Plate='CA', Plate Expiry Date='200316', Make='CHEV', Body Style='PA', Color='BK', Location='GEORGIA ST/OLYMPIC', Route='1FB70', Agency='1', Violation code='8069A', Violation Description='NO STOPPING/STANDING', Fine amount=93.0, Agency Description=None, Color Description=None, Body Style Description=None, color long='Black')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# B.8 Let’s expand some abbreviations in the color column. Create a User Defined Function to \n",
    "# create a new column, ‘color long’, mapping the original colors to their corresponding values\n",
    "# in the dictionary below. If there is no key matching the original color, use the original color. \n",
    "\n",
    "COLORS = {\n",
    "'AL':'Aluminum', 'AM':'Amber', 'BG':'Beige', 'BK':'Black',\n",
    "'BL':'Blue', 'BN':'Brown', 'BR':'Brown', 'BZ':'Bronze',\n",
    "'CH':'Charcoal', 'DK':'Dark', 'GD':'Gold', 'GO':'Gold',\n",
    "'GN':'Green', 'GY':'Gray', 'GT':'Granite', 'IV':'Ivory',\n",
    "'LT':'Light', 'OL':'Olive', 'OR':'Orange', 'MR':'Maroon',\n",
    "'PK':'Pink', 'RD':'Red', 'RE':'Red', 'SI':'Silver', 'SL':'Silver',\n",
    "'SM':'Smoke', 'TN':'Tan', 'VT':'Violet', 'WT':'White', 'WH':'White',\n",
    "'YL':'Yellow', 'YE':'Yellow', 'UN':'Unknown'\n",
    "}\n",
    " \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create function\n",
    "def color_long(val):\n",
    "    if val in COLORS:\n",
    "        return COLORS[val]\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "# Convert function to UDF\n",
    "color_long_UDF = udf(lambda x: color_long(x))\n",
    "\n",
    "# Apply the function\n",
    "df_with_color = df.withColumn(\"color long\", color_long_UDF(col(\"Color\")))\n",
    "\n",
    "# Check the first five values\n",
    "print(df_with_color.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d928653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gray', 489697), ('White', 434595), ('Black', 353812), ('Silver', 347894), ('Blue', 180091), ('Red', 119074), ('Green', 74968), ('Gold', 40646), ('Maroon', 26242), ('Tan', 23355)]\n"
     ]
    }
   ],
   "source": [
    "# B.9 Using this new column, what’s the most frequent colour value for Toyotas (TOYT)?\n",
    "\n",
    "top_color1 = df_with_color.filter(df['Make'] == 'TOYT')\n",
    "top_color2 = top_color1.rdd.map(lambda x: (x['color long'],1)).reduceByKey(lambda a, b: a+b)\n",
    "top_color3 = top_color2.sortBy(lambda x: x[1], ascending=False)\n",
    "print(top_color3.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce497eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5478247a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
